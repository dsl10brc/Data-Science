{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from sklearn.datasets.samples_generator import make_regression \n",
    "import pylab\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gradient_descent_2(alpha, x, y, numIterations):\n",
    "    m = x.shape[0] # number of samples\n",
    "    theta = np.ones(2)\n",
    "    x_transpose = x.transpose()\n",
    "    for iter in range(0, numIterations):\n",
    "        hypothesis = np.dot(x, theta)\n",
    "        print hypothesi, iter\n",
    "        loss = hypothesis - y\n",
    "        print loss \n",
    "        J = np.sum(loss ** 2) / (2 * m)  # cost\n",
    "        print J\n",
    "        print \"iter %s | J: %.3f\" % (iter, J)      \n",
    "        gradient = np.dot(x_transpose, loss) / m \n",
    "        print gradient\n",
    "        theta = theta - alpha * gradient  # update\n",
    "        print theta\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "    x, y = make_regression(n_samples=100, n_features=1, n_informative=1, \n",
    "                        random_state=0, noise=35) \n",
    "    m, n = np.shape(x)\n",
    "    x = np.c_[ np.ones(m), x] # insert column\n",
    "    alpha = 0.01 # learning rate\n",
    "    theta = gradient_descent_2(alpha, x, y, 1000)\n",
    "\n",
    "    # plot\n",
    "#     for i in range(x.shape[1]):\n",
    "#         y_predict = theta[0] + theta[1]*x \n",
    "#     pylab.plot(x[:,1],y,'o')\n",
    "#     pylab.plot(x,y_predict,'k-')\n",
    "#     pylab.show()\n",
    "#     print \"Done!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cluster_centroids(data, clusters, k=None):\n",
    "    \"\"\"Return centroids of clusters in data.\n",
    "\n",
    "    data is an array of observations with shape (A, B, ...).\n",
    "\n",
    "    clusters is an array of integers of shape (A,) giving the index\n",
    "    (from 0 to k-1) of the cluster to which each observation belongs.\n",
    "    The clusters must all be non-empty.\n",
    "\n",
    "    k is the number of clusters. If omitted, it is deduced from the\n",
    "    values in the clusters array.\n",
    "\n",
    "    The result is an array of shape (k, B, ...) containing the\n",
    "    centroid of each cluster.\n",
    "\n",
    "    >>> data = np.array([[12, 10, 87],\n",
    "    ...                  [ 2, 12, 33],\n",
    "    ...                  [68, 31, 32],\n",
    "    ...                  [88, 13, 66],\n",
    "    ...                  [79, 40, 89],\n",
    "    ...                  [ 1, 77, 12]])\n",
    "    >>> cluster_centroids(data, np.array([1, 1, 2, 2, 0, 1]))\n",
    "    array([[ 79.,  40.,  89.],\n",
    "           [  5.,  33.,  44.],\n",
    "           [ 78.,  22.,  49.]])\n",
    "\n",
    "    \"\"\"\n",
    "    if k is None:\n",
    "        k = np.max(clusters) + 1\n",
    "    result = np.empty(shape=(k,) + data.shape[1:])\n",
    "    print result,'result'\n",
    "    for i in range(k):\n",
    "        np.mean(data[clusters == i], axis=0, out=result[i])\n",
    "        print data,'data'\n",
    "        print result,'resulti'\n",
    "    return result\n",
    "\n",
    "import scipy.spatial\n",
    "\n",
    "def kmeans(data, k=None, centroids=None, steps=20):\n",
    "    \"\"\"Divide the observations in data into clusters using the k-means\n",
    "    algorithm, and return an array of integers assigning each data\n",
    "    point to one of the clusters.\n",
    "\n",
    "    centroids, if supplied, must be an array giving the initial\n",
    "    position of the centroids of each cluster.\n",
    "\n",
    "    If centroids is omitted, the number k gives the number of clusters\n",
    "    and the initial positions of the centroids are selected randomly\n",
    "    from the data.\n",
    "\n",
    "    The k-means algorithm adjusts the centroids iteratively for the\n",
    "    given number of steps, or until no further progress can be made.\n",
    "\n",
    "    >>> data = np.array([[12, 10, 87],\n",
    "    ...                  [ 2, 12, 33],\n",
    "    ...                  [68, 31, 32],\n",
    "    ...                  [88, 13, 66],\n",
    "    ...                  [79, 40, 89],\n",
    "    ...                  [ 1, 77, 12]])\n",
    "    >>> np.random.seed(73)\n",
    "    >>> kmeans(data, k=3)\n",
    "    array([1, 1, 2, 2, 0, 1])\n",
    "\n",
    "    \"\"\"\n",
    "    if centroids is not None and k is not None:\n",
    "        assert(k == len(centroids))\n",
    "    elif centroids is not None:\n",
    "        k = len(centroids)\n",
    "    elif k is not None:\n",
    "        # Forgy initialization method: choose k data points randomly.\n",
    "        centroids = data[np.random.choice(np.arange(len(data)), k, False)]\n",
    "#         print centroids, 'centroids'\n",
    "    else:\n",
    "        raise RuntimeError(\"Need a value for k or centroids.\")\n",
    "\n",
    "    for _ in range(max(steps, 1)):\n",
    "        # Squared distances between each point and each centroid.\n",
    "        sqdists = scipy.spatial.distance.cdist(centroids, data, 'sqeuclidean')\n",
    "#         print sqdists, 'sqdists'\n",
    "\n",
    "        # Index of the closest centroid to each data point.\n",
    "        clusters = np.argmin(sqdists, axis=0)\n",
    "#         print clusters, 'clusters'\n",
    "\n",
    "        new_centroids = cluster_centroids(data, clusters, k)\n",
    "#         print new_centroids, 'new_centroids'\n",
    "        if np.array_equal(new_centroids, centroids):\n",
    "            break\n",
    "\n",
    "        centroids = new_centroids\n",
    "\n",
    "    return clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "data = np.array([[12, 10, 87],[ 2, 12, 33],[68, 31, 32],[88, 13, 66],[79, 40, 89],[ 1, 77, 12]])\n",
    "np.random.seed(73)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "kmeans(data,k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "kmean(data,k=3,c=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# kmeans clustering algorithm\n",
    "# data = set of data points\n",
    "# k = number of clusters\n",
    "# c = initial list of centroids (if provided)\n",
    "#\n",
    "def kmean(data, k, c):\n",
    "    centroids = []\n",
    "\n",
    "    centroids = randomize_centroids(data, centroids, k)  \n",
    "    print centroids,'centroids'\n",
    "    old_centroids = [[] for i in range(k)] \n",
    "\n",
    "    iterations = 0\n",
    "    while not (has_converged(centroids, old_centroids, iterations)):\n",
    "        iterations += 1\n",
    "\n",
    "        clusters = [[] for i in range(k)]\n",
    "\n",
    "        # assign data points to clusters\n",
    "        clusters = euclidean_dist(data, centroids, clusters)\n",
    "        print clusters,'clusters'\n",
    "        # recalculate centroids\n",
    "        index = 0\n",
    "        for cluster in clusters:\n",
    "            old_centroids[index] = centroids[index]\n",
    "            print old_centroids[index],'old_centroids[index]'\n",
    "            centroids[index] = np.mean(cluster, axis=0).tolist()\n",
    "            print centroids[index],'centroids[index]'\n",
    "            index += 1\n",
    "\n",
    "\n",
    "    print(\"The total number of data instances is: \" + str(len(data)))\n",
    "    print(\"The total number of iterations necessary is: \" + str(iterations))\n",
    "    print(\"The means of each cluster are: \" + str(centroids))\n",
    "    print(\"The clusters are as follows:\")\n",
    "    for cluster in clusters:\n",
    "        print(\"Cluster with a size of \" + str(len(cluster)) + \" starts here:\")\n",
    "        print(np.array(cluster).tolist())\n",
    "        print(\"Cluster ends here.\")\n",
    "\n",
    "    return\n",
    "\n",
    "# Calculates euclidean distance between\n",
    "# a data point and all the available cluster\n",
    "# centroids.      \n",
    "def euclidean_dist(data, centroids, clusters):\n",
    "    for instance in data:  \n",
    "        # Find which centroid is the closest\n",
    "        # to the given data point.\n",
    "        mu_index = min([(i[0], np.linalg.norm(instance-centroids[i[0]])) \\\n",
    "                            for i in enumerate(centroids)], key=lambda t:t[1])[0]\n",
    "        try:\n",
    "            clusters[mu_index].append(instance)\n",
    "        except KeyError:\n",
    "            clusters[mu_index] = [instance]\n",
    "\n",
    "    # If any cluster is empty then assign one point\n",
    "    # from data set randomly so as to not have empty\n",
    "    # clusters and 0 means.        \n",
    "    for cluster in clusters:\n",
    "        if not cluster:\n",
    "            cluster.append(data[np.random.randint(0, len(data), size=1)].flatten().tolist())\n",
    "\n",
    "    return clusters\n",
    "\n",
    "\n",
    "# randomize initial centroids\n",
    "def randomize_centroids(data, centroids, k):\n",
    "    for cluster in range(0, k):\n",
    "        centroids.append(data[np.random.randint(0, len(data), size=1)].flatten().tolist())\n",
    "    return centroids\n",
    "\n",
    "\n",
    "# check if clusters have converged    \n",
    "def has_converged(centroids, old_centroids, iterations):\n",
    "    MAX_ITERATIONS = 1000\n",
    "    if iterations > MAX_ITERATIONS:\n",
    "        return True\n",
    "    return old_centroids == centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import h2o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# h2o.init(ip=\"127.0.0.1\",port=54321)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = np.array([[1, 2], [3, 4]])\n",
    "np.mean(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "print datetime.utcnow().strftime('%Y-%m-%d %H:%M:%S.%f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pytz import timezone\n",
    "amsterdam = timezone('Europe/Amsterdam')\n",
    "print datetime.now(amsterdam).strftime('%Y-%m-%d %H:%M:%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from time import gmtime, strftime\n",
    "print strftime(\"%Y-%m-%d %H:%M:%S\", gmtime())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pytz\n",
    "pytz.all_timezones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(filename='example.log',level=logging.DEBUG)\n",
    "# logging.debug('This message should go to the log file')\n",
    "# logging.info('So should this')\n",
    "# logging.warning('And this, too')\n",
    "def main():\n",
    "    try:\n",
    "        logging.debug(\"we are in the main loop\")\n",
    "        mathfail = 1/0\n",
    "    except Exception, e:\n",
    "        logging.critical(str(e))\n",
    "        \n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import smtplib\n",
    "\n",
    "# Import the email modules we'll need\n",
    "from email.mime.text import MIMEText\n",
    "\n",
    "# Open a plain text file for reading.  For this example, assume that\n",
    "# the text file contains only ASCII characters.\n",
    "fp = open('reard.txt', 'rb')\n",
    "# Create a text/plain message\n",
    "msg = MIMEText(fp.read())\n",
    "fp.close()\n",
    "\n",
    "# me == the sender's email address\n",
    "# you == the recipient's email address\n",
    "msg['Subject'] = 'The contents of %s' % textfile\n",
    "msg['From'] = deepsagar.lambor@gmail.com\n",
    "msg['To'] = you\n",
    "\n",
    "# Send the message via our own SMTP server, but don't include the\n",
    "# envelope header.\n",
    "s = smtplib.SMTP('localhost')\n",
    "s.sendmail(me, [you], msg.as_string())\n",
    "s.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import smtplib\n",
    "\n",
    "SERVER = \"localhost\"\n",
    "\n",
    "FROM = \"sender@example.com\"\n",
    "TO = [\"user@example.com\"] # must be a list\n",
    "\n",
    "SUBJECT = \"Hello!\"\n",
    "\n",
    "TEXT = \"This message was sent with Python's smtplib.\"\n",
    "\n",
    "# Prepare actual message\n",
    "\n",
    "message = \"\"\"\\\n",
    "From: %s\n",
    "To: %s\n",
    "Subject: %s\n",
    "\n",
    "%s\n",
    "\"\"\" % (FROM, \", \".join(TO), SUBJECT, TEXT)\n",
    "\n",
    "# Send the mail\n",
    "\n",
    "server = smtplib.SMTP(SERVER)\n",
    "server.sendmail(FROM, TO, message)\n",
    "server.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def send_email(user, pwd, recipient, subject, body):\n",
    "    import smtplib\n",
    "\n",
    "    gmail_user = user\n",
    "    gmail_pwd = pwd\n",
    "    FROM = user\n",
    "    TO = recipient if type(recipient) is list else [recipient]\n",
    "    SUBJECT = subject\n",
    "    TEXT = body\n",
    "\n",
    "    # Prepare actual message\n",
    "    message = \"\"\"\\From: %s\\nTo: %s\\nSubject: %s\\n\\n%s\n",
    "    \"\"\" % (FROM, \", \".join(TO), SUBJECT, TEXT)\n",
    "    try:\n",
    "        server = smtplib.SMTP(\"smtp.gmail.com\", 587)\n",
    "        server.ehlo()\n",
    "        server.starttls()\n",
    "        server.login(gmail_user, gmail_pwd)\n",
    "        server.sendmail(FROM, TO, message)\n",
    "        server.close()\n",
    "        print 'successfully sent the mail'\n",
    "    except:\n",
    "        print \"failed to send mail\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# gmail_user = 'nastbhagat@gmail.com'\n",
    "# gmail_pwd = 'chuckitmate'\n",
    "gmail_user = 'mailer@azumo.co'\n",
    "gmail_pwd = 'AzumoHQlogs'\n",
    "receipient = 'deepsagar@azumo.co'\n",
    "subject = 'ALERT: Error in the cralwer'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "body = 'There  is a following error in the crawler'\n",
    "send_email(gmail_user, gmail_pwd, receipient, subject, body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def send_email1(user, pwd, recipient, subject, body):\n",
    "    import smtplib\n",
    "\n",
    "    gmail_user = user\n",
    "    gmail_pwd = pwd\n",
    "    FROM = user\n",
    "    TO = recipient if type(recipient) is list else [recipient]\n",
    "    SUBJECT = subject\n",
    "    TEXT = body\n",
    "\n",
    "    # Prepare actual message\n",
    "    message = \"\"\"\\From: %s\\nTo: %s\\nSubject: %s\\n\\n%s\n",
    "    \"\"\" % (FROM, \", \".join(TO), SUBJECT, TEXT)\n",
    "    try:\n",
    "        server_ssl = smtplib.SMTP_SSL(\"smtp.gmail.com\", 465)\n",
    "        server_ssl.ehlo() # optional, called by login()\n",
    "        server_ssl.login(gmail_user, gmail_pwd)  \n",
    "        # ssl server doesn't support or need tls, so don't call server_ssl.starttls() \n",
    "        server_ssl.sendmail(FROM, TO, message)\n",
    "        #server_ssl.quit()\n",
    "        server_ssl.close()\n",
    "        print 'successfully sent the mail'\n",
    "        print 'successfully sent the mail'\n",
    "    except:\n",
    "        print \"failed to send mail\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "import traceback\n",
    "try:\n",
    "    urls = \"http://www.simplyhired.com/a/job-detaw/jobkey-67b4efe169eee7b2cf2ed47d49b1845070ea37/rid-racliggzfyjgqwfzrlvnqyjtcserhrri/cjp-3/pub_id-1002\"\n",
    "    site = urllib2.urlopen(urls).read()\n",
    "    mathfail = 1/0\n",
    "except Exception, e:\n",
    "    dld = traceback.format_exc()\n",
    "#         logging.exception(str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dld"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "job_descr = ''\n",
    "if job_descr:\n",
    "    print 'yes'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def text_cleaner(website):\n",
    "    '''\n",
    "    This function just cleans up the raw html so that I can look at it.\n",
    "    Inputs: a URL to investigate\n",
    "    Outputs: Cleaned text only\n",
    "    '''\n",
    "    try:\n",
    "        site = urllib2.urlopen(website).read() # Connect to the job posting\n",
    "    except: \n",
    "        return   # Need this in case the website isn't there anymore or some other weird connection problem \n",
    "    soup_obj = BeautifulSoup(site) # Get the html from the site\n",
    "    for script in soup_obj([\"script\", \"style\"]):\n",
    "        script.extract() # Remove these two elements from the BS4 object\n",
    "    text = soup_obj.get_text() # Get the text from this\n",
    "    lines = (line.strip() for line in text.splitlines()) # break into lines\n",
    "    chunks = (phrase.strip() for line in lines for phrase in line.split(\"  \")) # break multi-headlines into a line each\n",
    "    def chunk_space(chunk):\n",
    "        chunk_out = chunk + ' ' # Need to fix spacing issue\n",
    "        return chunk_out  \n",
    "    text = ''.join(chunk_space(chunk) for chunk in chunks if chunk).encode('utf-8') # Get rid of all blank lines and ends of line\n",
    "    # Now clean out all of the unicode junk (this line works great!!!)\n",
    "    try:\n",
    "        text = text.decode('unicode_escape').encode('ascii', 'ignore') # Need this as some websites aren't formatted\n",
    "    except:                                                            # in a way that this works, can occasionally throw\n",
    "        return                                                         # an exception\n",
    "    text = re.sub(\"[^a-zA-Z.+3]\",\" \", text)  # Now get rid of any terms that aren't words (include 3 for d3.js)\n",
    "                                                # Also include + for C++\n",
    "    text = text.lower().split()  # Go to lower case and split them apart\n",
    "    stop_words = set(stopwords.words(\"english\")) # Filter out any stop words\n",
    "    text = [w for w in text if not w in stop_words]\n",
    "    text = list(set(text)) # Last, just get the set of these. Ignore counts (we are just looking at whether a term existed\n",
    "                            # or not on the website)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup # For HTML parsing\n",
    "import urllib2 # Website connections\n",
    "import pandas as pd # For converting results to a dataframe and bar chart plots\n",
    "from urlparse import urlparse\n",
    "from django.utils.encoding import smart_str, smart_unicode\n",
    "import re\n",
    "import urllib\n",
    "from nltk.corpus import stopwords \n",
    "import json\n",
    "from pymongo import MongoClient\n",
    "from time import strftime\n",
    "import datetime\n",
    "from threading import Thread\n",
    "import time\n",
    "\n",
    "gh = 'https://www.ivyexec.com/professionals/jobs/job/3437588?ref=SIMPLYHIREDED&promo=SIMPLYHIREDED'\n",
    "job_descr = text_cleaner(gh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import mrjob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/deepu/anaconda/lib/python2.7/site-packages/sklearn/cross_validation.py:516: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of labels for any class cannot be less than n_folds=2.\n",
      "  % (min_labels, self.n_folds)), Warning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cross_validation import StratifiedKFold\n",
    "X = np.array([[1, 2], [3, 4], [5, 6], [7, 8]])\n",
    "y = np.array([0, 0, 9, 10])\n",
    "skf = StratifiedKFold(y, n_folds=2)\n",
    "len(skf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  1\n",
       "0  1  2\n",
       "1  3  4\n",
       "2  5  6\n",
       "3  7  8"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[1]</td>\n",
       "      <td>[0, 2, 3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0, 2, 3]</td>\n",
       "      <td>[1]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0          1\n",
       "0        [1]  [0, 2, 3]\n",
       "1  [0, 2, 3]        [1]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(list(skf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
